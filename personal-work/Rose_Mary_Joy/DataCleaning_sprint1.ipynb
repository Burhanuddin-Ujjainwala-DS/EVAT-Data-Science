{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa529862-5a2e-42be-85af-e71684ba15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data cleaning complete. Saved as 'Cleaned_EV_Charging_Sessions.csv'.\n",
      "Rows retained: 3395\n",
      "Rows with missing timestamps flagged: 3372\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"station_data_dataverse.csv\")\n",
    "\n",
    "# --- Step 1: Fix timestamp strings with known year error ---\n",
    "def fix_year_safe(ts):\n",
    "    if pd.isna(ts): return ts\n",
    "    return ts.replace(\"0014\", \"2014\")\n",
    "\n",
    "df['created'] = pd.to_datetime(df['created'].apply(fix_year_safe), errors='coerce')\n",
    "df['ended'] = pd.to_datetime(df['ended'].apply(fix_year_safe), errors='coerce')\n",
    "\n",
    "# --- Step 2: Convert chargeTimeHrs to numeric and recover missing durations ---\n",
    "df['chargeTimeHrs'] = pd.to_numeric(df['chargeTimeHrs'], errors='coerce')\n",
    "df.loc[df['chargeTimeHrs'].isna() & df['created'].notna() & df['ended'].notna(), 'chargeTimeHrs'] = \\\n",
    "    (df['ended'] - df['created']).dt.total_seconds() / 3600\n",
    "\n",
    "# --- Step 3: Clean and fill 'distance' ---\n",
    "df['distance'] = pd.to_numeric(df['distance'], errors='coerce')\n",
    "df['distance'].fillna(df['distance'].median(), inplace=True)\n",
    "\n",
    "# --- Step 4: Flag outliers and extract derived features ---\n",
    "df['isOutlier'] = df['chargeTimeHrs'] > 12\n",
    "df['hour'] = df['created'].dt.hour\n",
    "df['isWeekend'] = df['created'].dt.weekday >= 5\n",
    "df['dayOfWeek'] = df['created'].dt.day_name()\n",
    "\n",
    "# --- Step 5: Flag rows with both timestamps missing (retain them) ---\n",
    "df['timestamp_missing'] = df['created'].isna() & df['ended'].isna()\n",
    "\n",
    "# --- Step 6: Save cleaned dataset ---\n",
    "df.to_csv(\"Cleaned_EV_Charging_Sessions.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Data cleaning complete. Saved as 'Cleaned_EV_Charging_Sessions.csv'.\")\n",
    "print(f\"Rows retained: {df.shape[0]}\")\n",
    "print(f\"Rows with missing timestamps flagged: {df['timestamp_missing'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9137e7-8060-42cf-8f13-687626c720cd",
   "metadata": {},
   "source": [
    "EV Charger Pattern Analysis ‚Äì Data Cleaning Progress\n",
    "\n",
    "1. Dataset Loaded\n",
    "\n",
    "File: station_data_dataverse.csv\n",
    "\n",
    "Total rows: 3,395\n",
    "\n",
    "2. Timestamp Handling\n",
    "\n",
    "Replaced malformed '0014' with '2014' in timestamp fields\n",
    "\n",
    "Converted created and ended to proper datetime format\n",
    "\n",
    "Recalculated chargeTimeHrs where missing using ended - created\n",
    "\n",
    "3. Flagged Missing Timestamps\n",
    "\n",
    "Created a new column: timestamp_missing\n",
    "\n",
    "Flagged rows where both created and ended are missing (NaT)\n",
    "\n",
    "Flagged: 3,372 rows\n",
    "\n",
    "4. Distance Cleaning\n",
    "\n",
    "Converted distance to numeric format\n",
    "\n",
    "Imputed missing values using the median distance\n",
    "\n",
    "5. Outlier Detection\n",
    "\n",
    "Marked sessions with chargeTimeHrs > 12 hours as outliers\n",
    "\n",
    "6. Feature Extraction\n",
    "\n",
    "Extracted hour from created timestamp\n",
    "\n",
    "Derived isWeekend and dayOfWeek for user behavior analysis\n",
    "\n",
    "Time-based features are available for 23 valid timestamp rows\n",
    "\n",
    "7. Output Summary\n",
    "\n",
    "Cleaned dataset saved as: Cleaned_EV_Charging_Sessions.csv\n",
    "\n",
    "Total rows retained: 3,395\n",
    "\n",
    "Rows with valid timestamps: 23\n",
    "\n",
    "Dataset is fully usable for duration-based clustering; time-based clustering requires filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333b65b0-479a-48ef-803b-438986133d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.12.0-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.12.0-cp311-cp311-win_amd64.whl (846 kB)\n",
      "   ---------------------------------------- 0.0/846.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/846.0 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/846.0 kB 495.5 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 163.8/846.0 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 563.2/846.0 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  839.7/846.0 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  839.7/846.0 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 846.0/846.0 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "   ---------------------------------------- 0.0/313.6 kB ? eta -:--:--\n",
      "   --------------------------------------  307.2/313.6 kB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 313.6/313.6 kB 9.8 MB/s eta 0:00:00\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6e9b996-25ef-4b1d-bd6e-7b2d4b4a9cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded 3395 records to the collection.\n",
      "üîç Sample document inserted:\n",
      "{'_id': ObjectId('6802f8255d0e47f0f72d52fa')}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Connect to MongoDB ---\n",
    "client = MongoClient(\"mongodb+srv://EVAT:EVAT123@cluster0.5axoq.mongodb.net/EVAT?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client['EVAT']  # Replace with your actual database name if different\n",
    "\n",
    "# --- Step 2: Read your dataset ---\n",
    "df = pd.read_csv('Cleaned_EV_Charging_Sessions.csv')  # Replace with your actual CSV file name\n",
    "\n",
    "# --- Step 3: Choose or create collection ---\n",
    "collection = db['Cleaned_EV_Charging_Sessions']  # Replace with your target collection name\n",
    "\n",
    "# --- Step 4: Convert DataFrame to dictionary and upload ---\n",
    "data = df.to_dict(orient='records')\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(f\"‚úÖ Uploaded {len(data)} records to the collection.\")\n",
    "\n",
    "# --- üìù Step 5: Verification ---\n",
    "sample = collection.find_one()\n",
    "print(\"üîç Sample document inserted:\")\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd2e74-7833-482a-af18-32a0bc1e792d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
